---
layout: post
title:  "Vulnerability Analysis 101 - CVE-2020-16040"
date:   2020-12-08 17:30:00 +0800
---

# Introduction

I recently analyzed a really cool N-day vulnerability in V8 and wanted to blog about it, but I didn’t want it to just be your generic CVE analysis blog post. I wanted to add something extra, so I decided to also talk a little bit about the method that I generally use to analyze complex bugs like this one.

I’ll start out by covering some of the background knowledge required to understand this bug. Then, I'll talk about the method I use for analyzing bugs like this. Finally, I will go through how exactly I applied the method to analyze the bug in question. 

# Disclaimer

This is the method that I use, and I accept that it won’t necessarily work for everyone. This is by no means the absolute best way to analyze a bug, but the reason it works so well for me is because it forces me to do the following:

1. Read a lot of code to really understand not just what’s going on, but the internals of how the code is doing what it’s doing. This is really important to get a good feel for the code base, as it helps a ton when auditing the code base for bugs.
   
2. Experiment a lot with a debugger (which is GDB, in my case). This really teaches you things like how to inspect certain objects in memory (in the case of TurboFan, the most important object would be a Node object), where to set breakpoints to get execution to certain functions in the fastest way possible, and lots of other niche things, all of which really help when auditing for bugs.

If my method doesn’t work for you, then you should try to find a method that helps you achieve the same things (i.e lots of reading the code, lots of playing around in a debugger, etc). At the end of the day, it’s really all just a mindset. As long as it gets you reading the code and breaking down the bug in ways that help you understand it, you’ll be fine.

# CVE-2020-16040

On the 24th of November, a [very interesting V8 commit](https://chromium-review.googlesource.com/c/v8/v8/+/2557498) was made visible as part of [Chromium Issue 1150649](https://crbug.com/1150649) (which still hasn’t been disclosed). The commit seemed to patch a bug in the Simplified Lowering phase of V8’s optimizing JIT compiler, TurboFan. The latest V8 version that this bug affects is version **8.9.40**. I will be using this as the unpatched version for analysis, and I will be comparing things like Turbolizer output against version **8.9.41**, where the bug is fixed. 

The patch also included a nice regression test that showcased how to trigger the bug. It did not however grant any immediate exploitable primitives, so some work would need to be done to figure out whether the bug is exploitable at all (and how to exploit it).

Prior to analyzing this bug, I hadn’t really ever looked at the Simplified Lowering phase in detail, so I took this as the perfect opportunity to learn about it. There was also the added benefit of having to look at all the optimization phases that come *after* the Simplified Lowering phase in order to figure out whether this bug was exploitable or not. This would mean there would be tons of new things for me to learn, and that’s really all I aim for at the end of the day.

# Taking notes

One of the most important things to have when analyzing any bug is a nice, reliable way to take notes. I prefer Markdown syntax, so I usually just create a new Github repository for every bug that I analyze. You might prefer something like Google Docs, or OneNote, or etc, just pick whatever works for you.

**Do not skip this step**. Taking notes is going to be key to deeply understanding some of the most complex bugs, as it is next to impossible to remember everything about a bug when it takes days or weeks to analyze it. There’s just too much information to keep track of (trust me, I’ve tried :P), and your future self will be proud of you for keeping the notes when they end up having to look back at them to try to remember how something worked in detail.

# Background knowledge

Before actually starting to analyze the bug, it is helpful to have some background knowledge about the software that the bug applies to. In this case, having some knowledge of how TurboFan works, and more specifically knowledge of how the Simplified Lowering Phase works would be extremely helpful.

[Jeremy Fetiveau (@__x86)](https://twitter.com/__x86) recently [wrote a blog post that I would recommend to read](https://doar-e.github.io/blog/2020/11/17/modern-attacks-on-the-chrome-browser-optimizations-and-deoptimizations/). It has a section that talks about how the Simplified Lowering phase works in TurboFan. There are also a few other blog posts on that same blog (as well as online elsewhere) that cover topics like TurboFan’s typer, and etc.

Although I’ll try to explain everything that’s required to understand this specific bug, feel free to refer to other resources to understand what I’m trying to say. Information about complex topics is often really difficult to relay in a manner that’s comprehensible by everyone.

# First steps - coming up with some questions

The first thing that I always do is take all the information that I initially have about the bug that I’m analyzing, and come up with some exploratory questions that I’ll hopefully be able to answer after I’m done with my analysis. The exploratory nature of the questions should force me to really explore the code base (i.e read a lot of code).

How does this apply to this bug? Well, for starters, we have the patch, a commit message, and regression test. The regression test especially is very useful. If I didn’t have the regression test handy, then the first thing I’d do is try to figure out how to trigger the bug (which is easier said than done with something as complex as V8 / TurboFan). Since we have the regression test in this case though, I’ll just leave the whole “how to come up with a proof of concept” for another blog post.

Looking at the commit message, we see that it states the following:

```
[compiler] Fix a bug in SimplifiedLowering

SL's VisitSpeculativeIntegerAdditiveOp was setting Signed32 as restriction type even when 
relying on a Word32 truncation in order to skip the overflow check. This is not sound.
```

By itself, without any prior knowledge about the Simplified Lowering phase, this might be difficult to understand. We do know that patch modified a function called the `VisitSpeculativeIntegerAdditiveOp`, and that it has a nice comment that provides a bit more information:

```diff
+    // Using Signed32 as restriction type amounts to promising there won't be
+    // signed overflow. This is incompatible with relying on a Word32
+    // truncation in order to skip the overflow check.
+    Type const restriction =
+        truncation.IsUsedAsWord32() ? Type::Any() : Type::Signed32();
```

Right here, we have a few different terms such as “restriction type”, “Word32 truncation”, etc, that we have to learn about, but it should be pretty logical to conclude that the effect of the bug is this: the engine makes a promise and says that a signed integer overflow will not take place, but the actual outcome is that a signed integer overflow *does* take place.

Knowing this, let’s have a look at the regression test now. I added my own `assertTrue` and `assertFalse` functions to it so that I could actually run it (I believe ClusterFuzz does this automatically). Here is the modified one:

```js
// Copyright 2020 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

// Flags: --allow-natives-syntax

function assertTrue(c) {
    if (!c) { throw "Assertion failed"; }
}

function assertFalse(c) {
    assertTrue(!c);
}

function foo(a) {
  var y = 0x7fffffff;  // 2^31 - 1

  // Widen the static type of y (this condition never holds).
  if (a == NaN) y = NaN;

  // The next condition holds only in the warmup run. It leads to Smi
  // (SignedSmall) feedback being collected for the addition below.
  if (a) y = -1;

  const z = (y + 1)|0;
  return z < 0;
}

%PrepareFunctionForOptimization(foo);
assertFalse(foo(true));
%OptimizeFunctionOnNextCall(foo);
assertTrue(foo(false));
```

Looking at the code itself, we can quickly determine the following:

1. A variable `y` is set to `0x7fffffff`, which is `INT_MAX`.
2. Some TurboFan specific stuff is done which allows the bug to be triggered (we’ll get into all of this later).
3. A variable `z` is set to `(y + 1)|0`.
4. The return statement is supposed to return `false` for the first call to `foo` (The argument `a` will be `true`, so `y` will be set to `-1`, which will cause `z` to be set to `y+1 == -1+1 == 0`), which it does correctly.
5. For the second call to `foo`, `a` will be `false`, so `z` will be set to `y+1 == 0x7fffffff+1 == 0x80000000`. Based on the regression test, it seems this addition should yield the negative number `-2147483648`, which should cause the function to return `true` as this negative number is less than 0.
6. However, if you run this regression test, you’ll see that the final `assertTrue` will fail. We can conclude that the bug supposedly causes the engine to incorrectly assume that an integer overflow hasn’t occurred, when in fact it has (we haven’t verified yet that it has, but we will later).

Based on this information, I came up with the following questions that I will need to have answered after I’ve finished analyzing the bug:

* The “static type” of `y` is widened initially. The question is, how does this work? What is the “static type”, and why does it need to be widened here?
   
* In the warmup run (i.e the initial call to `foo`), `SignedSmall` feedback is collected by setting `y` to `-1`. Again, why is this required here? How does this specific line of code collect `SignedSmall` feedback?

* Why is `z` set to `(y + 1)|0`? More specifically, why is it bitwise OR’d with `0`?

These are the three questions I started with. Note how specific they are. It's these questions that help give me a goal to work towards. Of course, I had the initial goal of “analyse and understand this bug”, but personally that is a little too broad for me and not something that's directly achievable. Specific questions like these allow me to focus on one thing at a time, and as I figure out the answers, I'll slowly figure out the bug itself, which is the real end goal here.

# Unpatched vs Patched Turbolizer graphs

Before I started with answering the questions though, I wanted to quickly compare the Turbolizer graphs between the unpatched and patched versions of V8 to see exactly what effect the patch had on the engine. I won’t go into detail about how to use Turbolizer as there are many blog posts and guides out there.

When I looked at the graphs, I noted that the graphs looked the exact same during the Escape Analysis phase (which runs right before the Simplified Lowering phase). I'll only be showing the relevant parts of the graph here.

Escape Analysis Phase:

![](../images/cve-2020-16040/1.png)

A difference in the graph only shows in the Simplified Lowering phase. Here are the Simplified Lowering phases of both versions:

Unpatched Simplified Lowering Phase:

![](../images/cve-2020-16040/2.png)

Patched Simplified Lowering Phase:

![](../images/cve-2020-16040/3.png)

It's immediately evident that the `NumberLessThan` node from the Escape Analysis Phase has been changed to a `Uint32LessThan` node in the unpatched version's Simplified Lowering Phase. This node is used for the final `return z < 0` comparison. Presumably, the `Uint32LessThan` node means that TurboFan has failed to notice the integer overflow that occurs during the addition, as it attempts to compare the two numbers as unsigned 32-bit integers.

In contrast, the patched version's Simplified Lowering Phase will correctly compare the two numbers as signed 32-bit integers using the `Int32LessThan` node.

# Next steps

At this point, I started ticking the questions off one at a time. This required a lot of hours of tracing the code through the Simplified Lowering Phase, patching in some `printf` calls in various places to get more debug output, experimenting with stuff in GDB (like commenting out parts of the poc to see what would happen), etc.

Note that this is a tedious and long process, but I find this the best way to get an in-depth understanding of the code. I won't actually go through the entire process step by step (as I feel like that would make for a boring blog post). Instead, I'll cover the background knowledge required to answer the questions directly, which is what I assume most readers are here for anyway.

# The Simplified Lowering Phase

The core of the Simplified Lowering Phase happens in `src/compiler/simplified-lowering.cc`. In `src/compiler/pipeline.cc`, you'll note that that the Simplified Lowering Phase runs right after the Escape Analysis Phase:

```c++
bool PipelineImpl::OptimizeGraph(Linkage* linkage) {
  // [ ... ]

  if (FLAG_turbo_escape) {
    Run<EscapeAnalysisPhase>();
    // [ ... ]
  }

  // Perform simplified lowering. This has to run w/o the Typer decorator,
  // because we cannot compute meaningful types anyways, and the computed types
  // might even conflict with the representation/truncation logic.
  Run<SimplifiedLoweringPhase>(linkage);

  // [ ... ]
}
```

This will call into `SimplifiedLowering::Run`, which actually runs three sub-phases:

```c++
  void Run(SimplifiedLowering* lowering) {
    GenerateTraversal();
    RunPropagatePhase();
    RunRetypePhase();
    RunLowerPhase(lowering);
  }
```

`GenerateTraversal` will first put every node in the current graph into a vector called `traversal_nodes_`. It does this by doing a pre-order traversal starting from the `End` node, and pushing each node onto a temporary stack as they're visited. Nodes aren't pushed into the `traversal_nodes_` vector until all nodes have been visited. 

In short, this basically means that the `traversal_nodes_` vector can be iterated over from start to finish, and it'll essentially be the same as visually traversing the Turbolizer graph from top to bottom.

Next, the three sub-phases will run. In order to debug these sub-phases, the `--trace-representation` flag is really useful, as you'll soon see.

## The Propagation Phase

During this phase, the `traversal_nodes_` vector is traversed in reverse (i.e the first node that is visited will be the `End` node) while "truncations" are propagated through the graph.
  
Truncations can really just be thought of as a label that gets attached to a node, and then propagated to other nodes provided certain conditions are met. The truncations signify what "representation" a node should be restricted to. You can find a list of truncations defined in the `TruncationKind` enum:

```c++
  enum class TruncationKind : uint8_t {
    kNone,
    kBool,
    kWord32,
    kWord64,
    kOddballAndBigIntToNumber,
    kAny
  };
```

This truncation information (along with other information about the node, such as its feedback type, its restriction type, etc) are stored in a `NodeInfo` object, which can be accessed by calling `GetInfo(node)` on any `node`:

```c++
class RepresentationSelector {
 public:
  // Information for each node tracked during the fixpoint.
  class NodeInfo final {
   // [ ... ]
   private:
    enum State : uint8_t { kUnvisited, kPushed, kVisited, kQueued };
    State state_ = kUnvisited;
    MachineRepresentation representation_ =
        MachineRepresentation::kNone;             // Output representation.
    Truncation truncation_ = Truncation::None();  // Information about uses.

    Type restriction_type_ = Type::Any();
    Type feedback_type_;
    bool weakened_ = false;
  };
```

Note that when the Simplified Lowering Phase begins, all the fields you see above will be set to their default values (i.e The feedback type will be empty, the restriction type will be `Type::Any()`, etc). The fields are updated as each sub-phase is completed.

Let's go through a simplified example from the proof of concept code that we're provided with. We'll trace the `SpeculativeSafeIntegerAdd` node as that is the one that contains the bug (based on the patch), but of course I traced a lot more of the graph to really understand everything.

Running `d8` with `--trace-representation`, we get the following output:

```
--{Propagate phase}--
 [ ... ]
 visit #45: SpeculativeNumberBitwiseOr (trunc: truncate-to-word32)
  initial #43: truncate-to-word32
  initial #44: truncate-to-word32
  initial #43: truncate-to-word32
  initial #36: no-value-use
 visit #43: SpeculativeSafeIntegerAdd (trunc: truncate-to-word32)
  initial #39: no-truncation (but identify zeros)
  initial #42: no-truncation (but identify zeros)
  initial #22: no-value-use
  initial #36: no-value-use
 visit #42: NumberConstant (trunc: no-truncation (but identify zeros))
 visit #39: Phi (trunc: no-truncation (but identify zeros))
  initial #32: no-truncation (but identify zeros)
  initial #38: no-truncation (but identify zeros)
  initial #36: no-value-use
 [ ... ]
```

You can see that the `SpeculativeNumberBitwiseOr` node will propagate a `Word32` truncation to its first input (`#43`, the `SpeculativeSafeIntegerAdd` node), which will in turn propagate no truncations to its first two inputs. 

`RunPropagatePhase` will iterate over the `traversal_nodes_` vector backwards, and call `PropagateTruncation` on each node, which will in turn call `VisitNode<PROPAGATE>` on each node that is traversed. 

For the `SpeculativeSafeIntegerAdd` node, this method calls `VisitSpeculativeIntegerAdditiveOp`:

```c++
  template <Phase T>
  void VisitNode(Node* node, Truncation truncation,
                 SimplifiedLowering* lowering) {
    // [ ... ]
    switch (node->opcode()) {
      // [ ... ]
      case IrOpcode::kSpeculativeSafeIntegerAdd:
      case IrOpcode::kSpeculativeSafeIntegerSubtract:
        return VisitSpeculativeIntegerAdditiveOp<T>(node, truncation, lowering);
      // [ ... ]
    }
  }
```

`VisitSpeculativeIntegerAdditiveOp` is a bit of a long function, so I'll only show the relevant parts (and trim out any comments as well):

```c++
  template <Phase T>
  void VisitSpeculativeIntegerAdditiveOp(Node* node, Truncation truncation,
                                         SimplifiedLowering* lowering) {
    Type left_upper = GetUpperBound(node->InputAt(0));
    Type right_upper = GetUpperBound(node->InputAt(1));

    if (left_upper.Is(type_cache_->kAdditiveSafeIntegerOrMinusZero) &&
        right_upper.Is(type_cache_->kAdditiveSafeIntegerOrMinusZero)) {
      // [ ... ]
    }

    // [ ... ]
    return;
  }
```

First, the `left_upper` and `right_upper` are essentially just the types of the input nodes that you see on the Turbolizer graph in the Escape Analysis Phase.

* `left_upper` - The type of the `Phi` node, which is a `UnionType` of `NaN | Range(-1, 2147483647)`.
* `right_upper` - The type of the `NumberConstant[1]` node, which is just `Range(1, 1)`.

Next, the `if` branch at `[ 1 ]` will not be taken because the first check will fail. `kAdditiveSafeIntegerOrMinusZero` is a `UnionType` between a `Type::MinusZero()` and a `Range(-4503599627370496, 4503599627370496)`, but notice that it doesn't include `NaN`.

This actually answers a part of our first question. We know that the static type of `y` was widened by setting it to `NaN`. Since the first `if` statement is skipped specifically due to this reason, we can infer that this is done in order to get past the `if` statement (the function returns within the `if` branch and doesn't go any further). This is further confirmed by the patch, as the only changes to this function come *after* this `if` branch.

We can then also infer what a "static type" really is. In this case, it just seems like the static type is the type that is shown on the Turbolizer graph (i.e previously typed by the Typer Phase). The feedback type on the other hand seems to be a Simplified Lowering Phase specific thing (we'll look at it in more detail soon).

Next, we get to the following code, which helps answer our second question:

```c++
  template <Phase T>
  void VisitSpeculativeIntegerAdditiveOp(Node* node, Truncation truncation,
                                         SimplifiedLowering* lowering) {
    // [ ... ]
    NumberOperationHint hint = NumberOperationHintOf(node->op());
    DCHECK(hint == NumberOperationHint::kSignedSmall ||
           hint == NumberOperationHint::kSigned32);

    // [ ... ]
    return;
  }
```

We see that the `SpeculativeSafeIntegerAdd` node's `NumberOperationHint` is taken, and a `DCHECK` ensures that the hint is either a `kSignedSmall` or `kSigned32`. This tells us that in order to actually reach this code, we need either `SignedSmall` or `Signed32` feedback. Now we know why the proof of concept makes it a point to collect `SignedSmall` feedback in the warmup run.

This feedback can be seen being collected by Ignition (not important to trace this code, but as I said, I like answering every question thoroughly):

```c++
TNode<Object> BinaryOpAssembler::Generate_AddWithFeedback(
    TNode<Context> context, TNode<Object> lhs, TNode<Object> rhs,
    TNode<UintPtrT> slot_id, TNode<HeapObject> maybe_feedback_vector,
    bool rhs_known_smi) {
  // [ ... ]

    {
      // [ ... ]
      {
        var_type_feedback = SmiConstant(BinaryOperationFeedback::kSignedSmall); // [ 1 ]
        UpdateFeedback(var_type_feedback.value(), maybe_feedback_vector,
                       slot_id);
        var_result = smi_result;
        Goto(&end);
      }

      // [ ... ]
    }
  }
  // [ ... ]
```

With that out of the way, let's look at the next part of `VisitSpeculativeIntegerAdditiveOp`:

```c++
  template <Phase T>
  void VisitSpeculativeIntegerAdditiveOp(Node* node, Truncation truncation,
                                         SimplifiedLowering* lowering) {
    // [ ... ]

    Type left_constraint_type =
        node->opcode() == IrOpcode::kSpeculativeSafeIntegerAdd
            ? Type::Signed32OrMinusZero()
            : Type::Signed32();
    if (left_upper.Is(left_constraint_type) && /*[ ... ]*/) { // [ 1 ]
      // [ ... ]
    } else {
      IdentifyZeros left_identify_zeros = truncation.identify_zeros();
      if (node->opcode() == IrOpcode::kSpeculativeSafeIntegerAdd && // [ 2 ]
          !right_feedback_type.Maybe(Type::MinusZero())) {
        left_identify_zeros = kIdentifyZeros;
      }
      UseInfo left_use = CheckedUseInfoAsWord32FromHint(hint, FeedbackSource(),
                                                        left_identify_zeros);
      UseInfo right_use = CheckedUseInfoAsWord32FromHint(hint, FeedbackSource(),
                                                         kIdentifyZeros);
      VisitBinop<T>(node, left_use, right_use, MachineRepresentation::kWord32,
                    Type::Signed32());
    }

    // [ ... ]
    return;
  }
```

The `if` branch at `[ 1 ]` will not be taken since `left_upper.Is(Type::Signed32OrMinusZero())` will not pass for reasons explained above. Finally, we get to the `else` branch.

Before continuing, I'll briefly explain what "identifying zeros" vs "distinguishing zeros" means. Essentially, any truncation can have one of two options - to identify zeros or to distinguish between zeros. There is no real explanation (in the form of code comments or other blog posts) on this, but what I've inferred from reading a lot of the code is the following:

* Identify Zeros - This is the "default" option for most truncations.
* Distinguish zeros - This option seems to be used any time a truncation is being done on a node where distinguishing between `0` and `-0` is important.

The `truncation` argument that is passed into this function is the currently set truncation of the `SpeculativeSafeIntegerAdd` node. Remember that this is the first time the node has been visited, so the truncation will be a `TruncationKind::kNone`. This in turn means that `left_identify_zeros` will be set to `kIdentifyZeros` no matter whether the `if` branch at `[ 2 ]` is taken or not. 

Then, it will create `UseInfo` objects for the first and second input nodes using the `SignedSmall` hint. `CheckedUseInfoAsWord32FromHint` will call into `CheckSignedSmallAsWord32` for both inputs:

```c++
  static UseInfo CheckedSignedSmallAsWord32(IdentifyZeros identify_zeros,
                                            const FeedbackSource& feedback) {
    return UseInfo(MachineRepresentation::kWord32,
                   Truncation::Any(identify_zeros), TypeCheckKind::kSignedSmall,
                   feedback);
  }
```

We see that the `UseInfo` for both of the inputs have truncations set to `Truncation::Any(identify_zeros)`, where `identify_zeros` will be `kIdentifyZeros` in both cases.

Finally, `VisitBinop` is called. This is as follows:

```c++
  template <Phase T>
  void VisitBinop(Node* node, UseInfo left_use, UseInfo right_use,
                  MachineRepresentation output,
                  Type restriction_type = Type::Any()) {
    DCHECK_EQ(2, node->op()->ValueInputCount());
    ProcessInput<T>(node, 0, left_use);
    ProcessInput<T>(node, 1, right_use);
    for (int i = 2; i < node->InputCount(); i++) {
      EnqueueInput<T>(node, i);
    }
    SetOutput<T>(node, output, restriction_type);
  }
```

The first two inputs are processed using the `left_use` and `right_use` arguments. `ProcessInput` will call into `EnqueueInput`, which will essentially check whether the inputs have been visited before. If they haven't (which is the case here), then they are marked with the truncations that are set within `left_use` and `right_use` respectively. If they had been visited before, then they may or may not be added to a "revisit queue" to be revisited later.

Finally, any other existing inputs have `EnqueueInput` called on them (the third argument, if not provided, is set to `UseInfo::None()`). `SetOutput` will then set the `SpeculativeSafeIntegerAdd` node's output representation to `kWord32`, and its restriction type to `Type::Signed32()`.

Note that this call to `VisitBinop` is one of the lines that was modified by the patch. We'll see how the bug manifests because of this in the next sub-phase.

Every single node in the graph is visited in the same fashion as the `SpeculativeSafeIntegerAdd` node during the Propagation Phase. Once this has been done, the "revisit queue" mentioned earlier will be traversed if it isn't empty. After that, the Propagation Phase ends, and the Retype Phase begins.

## The Retype Phase

During this phase, the `traversal_nodes_` vector is traversed from start to finish. For each node that is visited, a new type is created using the types of the current node's inputs. Finally, this new type is intersected with the current node's restriction type (which was set during the Propagation Phase), and then the current node's feedback type (which can be found in its `NodeInfo` object) is updated with the new type.

Let's again look at the `SpeculativeSafeIntegerAdd` node as an example. The `--trace-representation` output tells us the following:

```
--{Retype phase}--
[ ... ]
#39:Phi[kRepTagged](#32:Phi, #38:NumberConstant, #36:Merge)  [Static type: (NaN | Range(-1, 2147483647))]
 visit #39: Phi                                                                 
  ==> output kRepFloat64                                                        
 visit #42: NumberConstant                                                      
  ==> output kRepTaggedSigned                                                   
#43:SpeculativeSafeIntegerAdd[SignedSmall](#39:Phi, #42:NumberConstant, #22:SpeculativeNumberEqual, #36:Merge)  [Static type: Range(0, 2147483648), Feedback type: Range(0, 2147483647)]
 visit #43: SpeculativeSafeIntegerAdd                                           
  ==> output kRepWord32
[ ... ]
```

We see that the first two inputs of the `SpeculativeSafeIntegerAdd` (which are the `Phi` and `NumberConstant` nodes) have both been retyped already. One thing to note here is that a `Feedback type` shown in the `--trace-representation` output essentially means that a new type **that is different to the original static type** was generated during the Retype phase.

In this case, for the `Phi` type, we see that only a static type is shown. This is slightly misleading, as it makes it seem like no feedback type was generated. However, this is would be incorrect. The `Phi` node has already been retyped, and its `NodeInfo` object will have its `feedback_type_` field updated to `NaN | Range(-1, 2147483647)`. It's just not shown in the output because the newly retyped type is the same as the original static type.

We also note that the `Phi` node's output representation is set to `kRepFloat64` (this is due to the `NaN` type), and that the `NumberConstant` node's output representation is set to `kRepTaggedSigned`.

Let's try to see how the `SpeculativeSafeIntegerAdd` node gets retyped, and why it has a feedback type that's different to its static type. Remember that the restriction type for this node has been set to `Type::Signed32()`, and its output representation is `kWord32`. 

The `RunRetypePhase` function calls `RetypeNode` as follows as follows:

```c++
  void RunRetypePhase() {
    TRACE("--{Retype phase}--\n");
    ResetNodeInfoState();
    DCHECK(revisit_queue_.empty());

    for (auto it = traversal_nodes_.cbegin(); it != traversal_nodes_.cend();
         ++it) {
      Node* node = *it;
      if (!RetypeNode(node)) continue;

      // Maybe revisit nodes if needed, not important
      // [ ... ]
    }
  }

  bool RetypeNode(Node* node) {
    NodeInfo* info = GetInfo(node);
    info->set_visited();
    bool updated = UpdateFeedbackType(node);
    TRACE(" visit #%d: %s\n", node->id(), node->op()->mnemonic());
    VisitNode<RETYPE>(node, info->truncation(), nullptr);
    TRACE("  ==> output %s\n", MachineReprToString(info->representation()));
    return updated;
  }
```

`RetypeNode` will first set the node to be "visited". Then, it will attempt to update the feedback type of the node using `UpdateFeedbackType`. Let's look at how this works:

```c++
  bool UpdateFeedbackType(Node* node) {
    if (node->op()->ValueOutputCount() == 0) return false;

    if (node->opcode() != IrOpcode::kPhi) { // [ 1 ]
      // [ ... ]
    }

    NodeInfo* info = GetInfo(node);
    Type type = info->feedback_type();
    Type new_type = NodeProperties::GetType(node);

    // We preload these values here to avoid increasing the binary size too
    // much, which happens if we inline the calls into the macros below.
    Type input0_type;
    if (node->InputCount() > 0) input0_type = FeedbackTypeOf(node->InputAt(0));
    Type input1_type;
    if (node->InputCount() > 1) input1_type = FeedbackTypeOf(node->InputAt(1));

    switch (node->opcode()) {
      // [ ... ]
#define DECLARE_CASE(Name)                                               \
  case IrOpcode::k##Name: {                                              \
    new_type = Type::Intersect(op_typer_.Name(input0_type, input1_type), \
                               info->restriction_type(), graph_zone());  \
    break;                                                               \
  }
      SIMPLIFIED_SPECULATIVE_NUMBER_BINOP_LIST(DECLARE_CASE)
      SIMPLIFIED_SPECULATIVE_BIGINT_BINOP_LIST(DECLARE_CASE)
#undef DECLARE_CASE

      // [ ... ]
    }
    new_type = Type::Intersect(GetUpperBound(node), new_type, graph_zone());

    if (!type.IsInvalid() && new_type.Is(type)) return false;
    GetInfo(node)->set_feedback_type(new_type);
    if (FLAG_trace_representation) {
      PrintNodeFeedbackType(node);
    }
    return true;
  }
```

The first `if` branch at `[ 1 ]` essentially ensures that every single input of this node has been retyped already. In our case, it has, so we can safely ignore it.

Next, we have two `Type` variables. `type` is the current feedback type of the node (which doesn't exist), while `new_type` is the current static type of the node (which is `Range(0, 2147483648)` from the Turbolizer graph).

Next, the feedback type of both inputs are stored in `input0_type` and `input1_type`. In this case, they're as follows:

* `input0_type` - `NaN | Range(-1, 2147483647)`
* `input1_type` - `Range(1, 1)`

Next, we get into a huge `switch` statement that makes extensive use of macros. In our case, we're interested in the one that handles `SIMPLIFIED_SPECULATIVE_NUMBER_BINOP_LIST`. In our case, the `new_type = ...` line of code essentially just translates to the following:

```c++
new_type =
    Type::Intersect(OperationTyper::SpeculativeSafeIntegerAdd(input0_type, input1_type), 
                    info->restriction_type(), graph_zone());
```

Here, `new_type` is essentially being set to the intersection of the current node's restriction type (which is `Type::Signed32()`, set during the Propagation Phase), and the type returned by `OperationTyper::SpeculativeSafeIntegerAdd`.

`OperationTyper::SpeculativeSafeIntegerAdd` is really simple. It will ignore the `NaN` type in `input0_type` and simply add the Min and Max of the ranges together, and return a new `RangeType`. Essentially return a `Range(-1+1, 2147483647+1)` == `Range(0, 2147483648)`.

Finally, when this new range is intersected with the restriction type, a final type of `Range(0, 2147483647)` is returned, which is what `new_type` gets set to. Feel free to trace through the code in `Type::Intersect` yourself, and you'll see how this works. In short, `Type::Signed32()` (i.e the restriction type) can be thought as a `Range(-2147483648, 2147483647)`. When intersected with `Range(0, 2147483648)`, the highest minimum and the lowest maximum is returned, which results in `Range(0, 2147483647)`.

At the very end of the function, the final `Type::Intersect` won't affect `new_type`. Then, the current node's feedback type is set to this new range.

**Note that this is the manifestation of the bug right here**. The feedback type is set to `Range(0, 2147483647)`, which is obviously incorrect. `input0_type`'s type was a `Range(-1, 2147483647)`. If it is the highest possible value (which it is in this case, `0x7fffffff` in the poc), then adding `1` to it will cause it to become `2147483648`, which will wrap around to `-2147483648`. This is not being covered in the final computed range that's being set as the node's feedback type.

This can be seen by returning and printing `z` from within the poc:

```js
function foo(a) {
  // [ ... ]
  return z;
}

%PrepareFunctionForOptimization(foo);
foo(true);
%OptimizeFunctionOnNextCall(foo);
print(foo(false));
```

```
$ ./d8 --allow-natives-syntax poc.js 
-2147483648
```

The root cause behind this is due to the restriction type being set to `Type::Signed32()`. Indeed, if you look at the patch, you'll note that it addresses this by setting the restriction type in `VisitSpeculativeIntegerAdditiveOp` to `Type::Any()` whenever the truncation is set to `kWord32`.

After this has been done, back in `RetypeNode`, `VisitNode` may or may not be called. In this case, it will, and it really only sets the current node's output representation to the current truncation value (which will be `kWord32`, same as before), so nothing really happens.

Once every single node has been retyped, some nodes may need to be revisited (similar to the Propagation Phase). After this is done, the Retype Phase ends, and the Lowering Phase begins.

## The Lowering Phase

I'll just summarize what happens in this phase since the bug has already been explained, although I should note that I did trace this phase as well just to make sure I understood it correctly.

Essentially, `RunLowerPhase` will iterate through the `traversal_nodes_` vector from the start to the end, and call `VisitNode<LOWER>` on each node. This will lower the node into a lower level node based on all the information that has been collected in the previous two sub-phases. 

For example, our `SpeculativeSafeIntegerAdd` node will be incorrectly lowered to an `Int32Add`, when in reality it should be lowered to a `CheckedInt32Add` due to the signed integer overflow.

This also explains why a `Uint32LessThan` node is inserted into the Simplified Lowering Phase of the unpatched version's Turbolizer graph. Since the engine thinks no overflow can possible occur, it won't bother with comparing signed integers. This can actually be seen in `VisitNode` inside the huge `switch` statement:

```c++
      case IrOpcode::kNumberLessThan:
      case IrOpcode::kNumberLessThanOrEqual: {
        Type const lhs_type = TypeOf(node->InputAt(0));
        Type const rhs_type = TypeOf(node->InputAt(1));
        // Regular number comparisons in JavaScript generally identify zeros,
        // so we always pass kIdentifyZeros for the inputs, and in addition
        // we can truncate -0 to 0 for otherwise Unsigned32 or Signed32 inputs.
        if (lhs_type.Is(Type::Unsigned32OrMinusZero()) &&
            rhs_type.Is(Type::Unsigned32OrMinusZero())) {
          // => unsigned Int32Cmp
          VisitBinop<T>(node, UseInfo::TruncatingWord32(),
                        MachineRepresentation::kBit);
          if (lower<T>()) NodeProperties::ChangeOp(node, Uint32Op(node));
        } else if (/*[ ... ]*/) {
            // [ ... ]
        }
        return;
      }
```

Here, `lhs` will be the type of the `SpeculativeNumberBitwiseOr` node, which will be `Range(0, 2147483647)`, while `rhs` will be a `Range(0, 0)`. Since both of these types fit in an `Unsigned32`, the first `if` branch will be taken. As you can see, during the Lowering Phase, `if (lower<T>())` will return true, and the current node will be changed to its `Uint32` version.

